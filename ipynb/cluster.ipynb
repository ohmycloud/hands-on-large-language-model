{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyhPlTz8b0Wf"
      },
      "outputs": [],
      "source": [
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "!uv init\n",
        "!uv add torch\n",
        "!uv add transformers\n",
        "!uv add numpy\n",
        "!uv add tqdm\n",
        "!uv add bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP6QFzrDiPm9"
      },
      "outputs": [],
      "source": [
        "# 从 Hugging Face 加载数据\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "import numpy as np\n",
        "\n",
        "dataset = load_dataset(\"maartengr/arxiv_nlp\")[\"train\"]\n",
        "\n",
        "# 提取元数据\n",
        "abstracts = dataset[\"Abstracts\"]\n",
        "titles = dataset[\"Titles\"]\n",
        "\n",
        "# 为每个摘要创建嵌入向量\n",
        "embedding_model = SentenceTransformer(\"thenlper/gte-small\")\n",
        "embeddings = embedding_model.encode(abstracts, show_progress_bar=True)\n",
        "embeddings.shape\n",
        "\n",
        "# 将输入嵌入向量从 384维降到5维\n",
        "umap_model = UMAP(\n",
        "    n_components=5,\n",
        "    min_dist=0.0,\n",
        "    metric=\"cosine\",\n",
        "    random_state=42\n",
        ")\n",
        "reduced_embeddings = umap_model.fit_transform(embeddings)\n",
        "\n",
        "# 对降维后的嵌入向量进行聚类\n",
        "# 拟合模型并提取簇\n",
        "hdbscan_model = HDBSCAN(\n",
        "    min_cluster_size=50,\n",
        "    metric=\"euclidean\",\n",
        "    cluster_selection_method=\"eom\"\n",
        ").fit(reduced_embeddings)\n",
        "clusters = hdbscan_model.labels_\n",
        "\n",
        "# 我们生成了多少个簇\n",
        "len(set(clusters))\n",
        "\n",
        "# 打印簇0中的前三个文档\n",
        "cluster = 0\n",
        "for index in np.where(clusters==cluster)[0][:3]:\n",
        "  print(abstracts[int(index)][:300] + \"... \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 将384 维的嵌入向量降至二维以便于可视化\n",
        "\n",
        "reduced_embeddings = UMAP(\n",
        "    n_components=2,\n",
        "    min_dist=0.0,\n",
        "    metric=\"cosine\",\n",
        "    random_state=42\n",
        ").fit_transform(embeddings)\n",
        "\n",
        "# 创建 DataFrame\n",
        "df = pd.DataFrame(reduced_embeddings, columns=[\"x\", \"y\"])\n",
        "df[\"title\"] = titles\n",
        "df[\"cluster\"] = [str(c) for c in clusters]\n",
        "\n",
        "# 选择离群点和非离群点（聚类）\n",
        "clusters_df = df.loc[df.cluster != \"-1\", :]\n",
        "outliers_df = df.loc[df.cluster == \"-1\", :]\n",
        "\n",
        "# 分别绘制离群点和非离群点\n",
        "plt.scatter(outliers_df.x, outliers_df.y, alpha=0.05, s=2, c=\"grey\")\n",
        "plt.scatter(clusters_df.x, clusters_df.y, c=clusters_df.cluster.astype(int), alpha=0.6, s=2, cmap=\"tab20b\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Baw8_d9R7Zqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic"
      ],
      "metadata": {
        "id": "qDw-so4vTdMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "# 使用之前定义的模型训练我们的模型\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=embedding_model,\n",
        "    umap_model=umap_model,\n",
        "    hdbscan_model=hdbscan_model,\n",
        "    verbose=True\n",
        ").fit(abstracts, embeddings)\n",
        "\n",
        "topic_model.get_topic_info()\n",
        "topic_model.get_topic(0)\n",
        "topic_model.find_topics(\"topic modeing\")\n",
        "topic_model.get_topic(22)\n",
        "topic_model.topics_[titles.index(\"BERTopic: Neural topic modeling with a class-based TF-IDF procedure\")]"
      ],
      "metadata": {
        "id": "R0y0glJYI1XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 可视化主题和文档\n",
        "fig = topic_model.visualize_documents(\n",
        "    titles,\n",
        "    reduced_embeddings=reduced_embeddings,\n",
        "    width=1200,\n",
        "    hide_annotations=True\n",
        ")\n",
        "\n",
        "# 更新图例字体设置以便于可视化\n",
        "fig.update_layout(font=dict(size=16))\n",
        "\n",
        "# 可视化带有关键词排名的条形图\n",
        "topic_model.visualize_barchart()\n",
        "\n",
        "# 可视化主题之间的关系\n",
        "topic_model.visualize_heatmap(n_clusters=30)\n",
        "\n",
        "# 可视化主题的潜在层次结构\n",
        "topic_model.visualize_hierarchy()"
      ],
      "metadata": {
        "id": "Iw2gCEYebXYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存原始表示\n",
        "from copy import deepcopy\n",
        "from bertopic.representation import KeyBERTInspired\n",
        "\n",
        "original_topics = deepcopy(topic_model.topic_representations_)\n",
        "\n",
        "def topic_differences(model, original_topics, nr_topics=5):\n",
        "  \"\"\"显示两个模型之间主题表示的差异\"\"\"\n",
        "  df = pd.DataFrame(columns=[\"Topic\", \"Original\", \"Updated\"])\n",
        "\n",
        "  for topic in range(nr_topics):\n",
        "    # 每个模型、每个主题提取前5个词\n",
        "    og_words = \" | \".join(list(zip(*original_topics[topic]))[0][:5])\n",
        "    new_words = \" | \".join(list(zip(*model.get_topic(topic)))[0][:5])\n",
        "    df.loc[len(df)] = [topic, og_words, new_words]\n",
        "\n",
        "# 使用 KeyBERTInspired 更新主题表示\n",
        "representation_model = KeyBERTInspired()\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "# 展示主题差异\n",
        "topic_differences(topic_model, original_topics)"
      ],
      "metadata": {
        "id": "Xfv7O95PeqA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic.representation import MaximalMarginalRelevance\n",
        "\n",
        "# 将主题表示更新为最大边际相关性\n",
        "representation_model = MaximalMarginalRelevance(diversity=0.2)\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "# 展示主题差异\n",
        "topic_differences(topic_model, original_topics)"
      ],
      "metadata": {
        "id": "AXVtv6qTidCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from bertopic.representation import TextGeneration\n",
        "\n",
        "prompt = \"\"\"I have a topic that contains the following documents:\n",
        "         [DOCUMENTS]\n",
        "         The topic is described by the following keywords: '[KEYWORDS]'.\n",
        "         Based on the documents and keywords, what is this topic about?\n",
        "         \"\"\"\n",
        "# 使用 FLAN-T5 更新主题表示\n",
        "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
        "representation_model = TextGeneration(\n",
        "    generator,\n",
        "    prompt=prompt,\n",
        "    doc_length=50,\n",
        "    tokenizer=\"shitespace\"\n",
        ")\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "\n",
        "# 展示主题差异\n",
        "topic_differences(topic_model, original_topics)"
      ],
      "metadata": {
        "id": "6gcG-9yfmKvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from bertopic.representation import OpenAI\n",
        "\n",
        "prompt = \"\"\"I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "The topic is described by the following keywords: [KEYWORDS]\n",
        "Based on the information above, extract a short topic label in the following\n",
        "format:\n",
        "topic: <short topic label>\n",
        "\"\"\"\n",
        "# 使用 GPT-3.5 更新主题表示\n",
        "client = openai.OpenAI(\n",
        "    api_key=\"sk-o5h8qo4udMjKiARF318d3829EdD74d8aB891CcD86b7a6e0b\",\n",
        "    base_url=\"https://api.apiyi.com/v1\"\n",
        ")\n",
        "\n",
        "representation_model = OpenAI(\n",
        "    client,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    exponential_backoff=True,\n",
        "    chat=True,\n",
        "    prompt=prompt\n",
        ")\n",
        "\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "\n",
        "# 展示主题差异\n",
        "topic_differences(topic_model, original_topics)"
      ],
      "metadata": {
        "id": "DyqYe5wMncT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datamapplot"
      ],
      "metadata": {
        "id": "wGQk-bfOZAhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datamapplot\n",
        "\n",
        "# 可视化主题和文档\n",
        "fig = topic_model.visualize_document_datamap(\n",
        "    titles,\n",
        "    topics=list(range(20)),\n",
        "    reduced_embeddings=reduced_embeddings,\n",
        "    # label_font_size=11,\n",
        "    # use_medoids=True,\n",
        ")"
      ],
      "metadata": {
        "id": "GoCuZn-QojN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6I82PBbMe5lL"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
