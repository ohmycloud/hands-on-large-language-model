{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d012415",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add ipykernel\n",
    "!uv add torch\n",
    "!uv add transformers\n",
    "!uv add numpy\n",
    "!uv add tqdm\n",
    "!uv add llama_cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16835f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import gc\n",
    "\n",
    "# 清理缓存\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# 加载模型和分词器\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\", \n",
    "    device_map=\"cuda\",\n",
    "    dtype=\"auto\", \n",
    "    trust_remote_code=False,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\"\n",
    ")\n",
    "\n",
    "# 创建文本生成管道\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.9,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "# 提示词\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n",
    "]\n",
    "\n",
    "# 生成输出\n",
    "output = pipe(messages)\n",
    "print(output[0][\"generated_text\"])\n",
    "\n",
    "# 应用提示词模板\n",
    "prompt = pipe.tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用虚构词的单个句子示例\n",
    "one_shot_prompt = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"A 'Gigamuru' is a type of Japanese musical instrument. An example of a sentence that uses the word Gigamuru is:\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I have a Gigamuru that my uncle gave me as a gift. I love to play it at home.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"To 'screeg' something is to swing a sword at it. An example of a sentence that uses the word screeg is:\"\n",
    "    }\n",
    "]\n",
    "print(tokenizer.apply_chat_template(one_shot_prompt, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为产品创建名称和口号\n",
    "product_prompt = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Create a name and slogan for a chatbot that leverages LLMs.\"\n",
    "    }\n",
    "]\n",
    "outputs = pipe(product_prompt)\n",
    "product_description = outputs[0][\"generated_text\"]\n",
    "print(product_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于产品名称和口号生成销售宣传语\n",
    "sales_prompt = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Generate a very short sales pitch for the following product: {product_description}\"\n",
    "    }\n",
    "]\n",
    "outputs = pipe(sales_prompt)\n",
    "sales_pitch = outputs[0][\"generated_text\"]\n",
    "print(sales_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1be396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用思维链回答\n",
    "cot_prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\"},\n",
    "    {\"role\": \"user\", \"content\": \"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"}\n",
    "]\n",
    "# 生成输出\n",
    "outputs = pipe(cot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 零样本思维链\n",
    "zeroshot_cot_prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have? Let's think step-by-step.\"}\n",
    "]\n",
    "# 生成输出\n",
    "outputs = pipe(zeroshot_cot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c786d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 零样本思维树\n",
    "zeroshot_tot_prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"Imagine three different experts are answering this question. All experts will write down 1 step of their thinking, then share it with the group. Then all experts will go on to the next step, etc. If any expert realizes they're wrong at any point then they leave. The question is 'The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?' Make sure to discuss the results.\"}\n",
    "]\n",
    "# 生成输出\n",
    "outputs = pipe(zeroshot_tot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba53e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 零样本学习：不提供示例\n",
    "zeroshot_prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"Create a character profile for an RPG game in JSON format.\"}\n",
    "]\n",
    "# 生成输出\n",
    "outputs = pipe(zeroshot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6123506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单样本学习：提供输出结构示例\n",
    "one_shot_template = \"\"\"Create a short character profile for an RPG game. Make sure to only use this format:\n",
    "{\n",
    "  \"description\": \"A SHORT DESCRIPTION\",\n",
    "  \"name\": \"THE CHARACTER'S NAME\",\n",
    "  \"armor\": \"ONE PIECE OF ARMOR\",\n",
    "  \"weapon\": \"ONE OR MORE WEAPONS\"\n",
    "}\n",
    "\"\"\"\n",
    "one_shot_prompt = [\n",
    "    {\"role\": \"user\", \"content\": one_shot_template}\n",
    "]\n",
    "# 生成输出\n",
    "outputs = pipe(one_shot_prompt)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeefc40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "del model, tokenizer, pipe\n",
    "\n",
    "# 清理缓存和显存\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from llama_cpp.llama import Llama\n",
    "\n",
    "# 加载 Phi-3\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"microsoft/Phi-3-mini-4k-instruct-gguf\",\n",
    "    filename=\"*fp16.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    n_ctx=2048,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 生成输出\n",
    "output = llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Create a warrior for an RGP in JSON format.\"},\n",
    "    ],\n",
    "    response_format={\"type\": \"jons_object\"},\n",
    "    temperature=0,\n",
    ")[\"choices\"][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_output = json.dumps(json.loads(output), indent=4)\n",
    "print(json_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands-on-large-language-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
