{"cells":[{"cell_type":"markdown","id":"zhCKqVAkLoO_","metadata":{"id":"zhCKqVAkLoO_"},"source":["# 添加依赖"]},{"cell_type":"code","execution_count":null,"id":"LZRWk2llKj4n","metadata":{"id":"LZRWk2llKj4n"},"outputs":[],"source":["!uv init\n","!uv add sentence-transformers\n","!uv add datasets\n","!uv add torch\n","!uv add mteb\n","!uv add tqdm"]},{"cell_type":"markdown","id":"ujvdOYNKLvNa","metadata":{"id":"ujvdOYNKLvNa"},"source":["# 加载数据集"]},{"cell_type":"code","execution_count":null,"id":"de0610f8","metadata":{"id":"de0610f8"},"outputs":[],"source":["from datasets import load_dataset\n","\n","# 从GLUE加载MNLI数据集\n","# 0 = 蕴含，1 = 中性，2 = 矛盾\n","train_dataset = load_dataset(\n","    \"glue\", \"mnli\", split=\"train\"\n",").select(range(50_000))\n","train_dataset = train_dataset.remove_columns(\"idx\")"]},{"cell_type":"code","execution_count":null,"id":"ab8333a6","metadata":{"id":"ab8333a6"},"outputs":[],"source":["train_dataset[2]"]},{"cell_type":"code","execution_count":null,"id":"ecba85c2","metadata":{"id":"ecba85c2"},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","\n","# 使用一个基座模型\n","embedding_model = SentenceTransformer('bert-base-uncased')"]},{"cell_type":"code","execution_count":null,"id":"1994929e","metadata":{"id":"1994929e"},"outputs":[],"source":["from sentence_transformers import losses\n","\n","# 定义损失函数。在softmax损失函数中，我们还需要显式设置标签数量\n","train_loss = losses.SoftmaxLoss(\n","    model=embedding_model,\n","    sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(),\n","    num_labels=3\n",")"]},{"cell_type":"code","execution_count":null,"id":"b65c0725","metadata":{"id":"b65c0725"},"outputs":[],"source":["from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n","\n","# 为STSB创建嵌入相似度评估器\n","val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n","evaluator = EmbeddingSimilarityEvaluator(\n","    sentences1=val_sts[\"sentence1\"],\n","    sentences2=val_sts[\"sentence2\"],\n","    scores=[score/5 for score in val_sts[\"label\"]],\n","    main_similarity=\"cosine\",\n",")"]},{"cell_type":"code","execution_count":null,"id":"3c2608d2","metadata":{"id":"3c2608d2"},"outputs":[],"source":["from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n","\n","# 定义训练参数\n","args = SentenceTransformerTrainingArguments(\n","    output_dir=\"base_embedding_model\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    warmup_steps=100,\n","    fp16=True,\n","    eval_steps=100,\n","    logging_steps=100,\n",")"]},{"cell_type":"code","execution_count":null,"id":"5e0a1a1e","metadata":{"id":"5e0a1a1e"},"outputs":[],"source":["from sentence_transformers.trainer import SentenceTransformerTrainer\n","\n","# 训练嵌入模型\n","trainer = SentenceTransformerTrainer(\n","    model=embedding_model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    loss=train_loss,\n","    evaluator=evaluator\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"45352e59","metadata":{"id":"45352e59"},"outputs":[],"source":["# 评估我们训练好的模型\n","evaluator(embedding_model)"]},{"cell_type":"markdown","id":"676fb1d4","metadata":{"id":"676fb1d4"},"source":["# 为了公开比较前沿嵌入模型的性能，业界建立了MTEB排行榜，展示了各嵌入模型在相关任务上的得分"]},{"cell_type":"code","execution_count":null,"id":"40bc23ea","metadata":{"id":"40bc23ea"},"outputs":[],"source":["import mteb\n","\n","# 选择模型\n","model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n","model = mteb.get_model(model_name) # if the model is not implemented in MTEB it will be eq. to SentenceTransformer(model_name)\n","\n","\n","# 选择评估任务\n","tasks = mteb.get_tasks(tasks=[\"Banking77Classification.v2\"])\n","\n","# 计算结果\n","results = mteb.evaluate(model, tasks=tasks)\n","results"]},{"cell_type":"code","execution_count":null,"id":"e46cbcf9","metadata":{"id":"e46cbcf9"},"outputs":[],"source":["from datasets import Dataset, load_dataset\n","\n","# 从GLUE加载MNLI数据集\n","# 0 = 蕴含, 1 = 中性, 2 = 矛盾\n","train_dataset = load_dataset(\n","    \"glue\", \"mnli\", split=\"train\"\n",").select(range(50_000))\n","train_dataset = train_dataset.remove_columns(\"idx\")\n","\n","# 中性/矛盾=0，蕴含=1\n","mapping = {2: 0, 1: 0, 0:1}\n","train_dataset = Dataset.from_dict({\n","    \"sentence1\": train_dataset[\"premise\"],\n","    \"sentence2\": train_dataset[\"hypothesis\"],\n","    \"label\": [float(mapping[label]) for label in train_dataset[\"label\"]]\n","})"]},{"cell_type":"code","execution_count":null,"id":"35dacdd3","metadata":{"id":"35dacdd3"},"outputs":[],"source":["from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n","\n","# 为STSB创建嵌入相似度评估器\n","val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n","evaluator = EmbeddingSimilarityEvaluator(\n","    sentences1=val_sts[\"sentence1\"],\n","    sentences2=val_sts[\"sentence2\"],\n","    scores=[score/5 for score in val_sts[\"label\"]],\n","    main_similarity=\"cosine\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"ffc0215f","metadata":{"id":"ffc0215f"},"outputs":[],"source":["from sentence_transformers import losses, SentenceTransformer\n","from sentence_transformers.trainer import SentenceTransformerTrainer\n","from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n","\n","# 定义模型\n","embedding_model = SentenceTransformer(\"bert-base-uncased\")\n","# 损失函数\n","train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n","# 定义训练参数\n","args = SentenceTransformerTrainingArguments(\n","    output_dir=\"cosineloss_embedding_model\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    warmup_steps=100,\n","    fp16=True,\n","    eval_steps=100,\n","    logging_steps=100,\n",")\n","# 训练模型\n","trainer = SentenceTransformerTrainer(\n","    model=embedding_model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    loss=train_loss,\n","    evaluator=evaluator\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"ba8b1a0d","metadata":{"id":"ba8b1a0d"},"outputs":[],"source":["# 评估我们训练的模型\n","evaluator(embedding_model)"]},{"cell_type":"code","execution_count":null,"id":"8Z6kV4c53cQu","metadata":{"id":"8Z6kV4c53cQu"},"outputs":[],"source":["import random\n","from tqdm import tqdm\n","from datasets import Dataset, load_dataset\n","\n","# 从GLUE加载MNLI数据集\n","mnli = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n","mnli = mnli.remove_columns(\"idx\")\n","mnli = mnli.filter(lambda x: True if x[\"label\"] == 0 else False)\n","# 准备数据并添加软负例\n","train_dataset = {\"anchor\": [], \"positive\": [], \"negative\": []}\n","soft_negatives = list(mnli[\"hypothesis\"])  # 添加 list() 转换\n","random.shuffle(soft_negatives)\n","\n","for row, soft_negative in tqdm(zip(mnli, soft_negatives)):\n","    train_dataset[\"anchor\"].append(row[\"premise\"])\n","    train_dataset[\"positive\"].append(row[\"hypothesis\"])\n","    train_dataset[\"negative\"].append(soft_negative)\n","train_dataset = Dataset.from_dict(train_dataset)"]},{"cell_type":"code","execution_count":null,"id":"uABofT7Y452q","metadata":{"id":"uABofT7Y452q"},"outputs":[],"source":["from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n","\n","# 为STSB创建嵌入相似度评估器\n","val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n","evaluator = EmbeddingSimilarityEvaluator(\n","    sentences1=val_sts[\"sentence1\"],\n","    sentences2=val_sts[\"sentence2\"],\n","    scores=[score/5 for score in val_sts[\"label\"]],\n","    main_similarity=\"cosine\"\n",")"]},{"cell_type":"markdown","id":"Zev-XAK14-1r","metadata":{"id":"Zev-XAK14-1r"},"source":["# 像之前一样进行训练，但使用MNR损失函数"]},{"cell_type":"code","execution_count":null,"id":"ppPvRcfr4_ST","metadata":{"id":"ppPvRcfr4_ST"},"outputs":[],"source":["from sentence_transformers import losses, SentenceTransformer\n","from sentence_transformers.trainer import SentenceTransformerTrainer\n","from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n","\n","# 定义模型\n","embedding_model = SentenceTransformer('bert-base-uncased')\n","# 损失函数\n","train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)\n","# 定义训练参数\n","args = SentenceTransformerTrainingArguments(\n","    output_dir=\"mnrloss_embedding_model\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    warmup_steps=100,\n","    fp16=True,\n","    eval_steps=100,\n","    logging_steps=100,\n",")\n","# 训练模型\n","trainer = SentenceTransformerTrainer(\n","    model=embedding_model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    loss=train_loss,\n","    evaluator=evaluator\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"aAZXDhFi5Qr1","metadata":{"id":"aAZXDhFi5Qr1"},"outputs":[],"source":["# 评估我们训练的模型\n","evaluator(embedding_model)"]},{"cell_type":"code","execution_count":null,"id":"26TK_llSBpHh","metadata":{"id":"26TK_llSBpHh"},"outputs":[],"source":["from datasets import load_dataset\n","from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n","\n","# 从GLUE加载MNLI数据集\n","# 0 = 蕴含, 1 = 中性, 2 = 矛盾\n","train_dataset = load_dataset(\n","    \"glue\", \"mnli\", split=\"train\"\n",").select(range(50_000))\n","train_dataset = train_dataset.remove_columns(\"idx\")\n","# 为STSB创建嵌入相似度评估器\n","val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n","evaluator = EmbeddingSimilarityEvaluator(\n","    sentences1=val_sts[\"sentence1\"],\n","    sentences2=val_sts[\"sentence2\"],\n","    scores=[score/5 for score in val_sts[\"label\"]],\n","    main_similarity=\"cosine\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"dA5rQtaWCGH_","metadata":{"id":"dA5rQtaWCGH_"},"outputs":[],"source":["from sentence_transformers import losses, SentenceTransformer\n","from sentence_transformers.trainer import SentenceTransformerTrainer\n","from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n","\n","# 定义模型\n","embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","# 损失函数\n","train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)\n","# 定义训练参数\n","args = SentenceTransformerTrainingArguments(\n","    output_dir=\"finetuned_embedding_model\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    warmup_steps=100,\n","    fp16=True,\n","    eval_steps=100,\n","    logging_steps=100,\n",")\n","# 训练模型\n","trainer = SentenceTransformerTrainer(\n","    model=embedding_model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    loss=train_loss,\n","    evaluator=evaluator\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"GSCDuUbRCK4u","metadata":{"id":"GSCDuUbRCK4u"},"outputs":[],"source":["# 评估我们训练的模型\n","evaluator(embedding_model)"]},{"cell_type":"markdown","id":"VvJzLgL_Ce8i","metadata":{"id":"VvJzLgL_Ce8i"},"source":["# 增强型SBERT"]},{"cell_type":"code","execution_count":null,"id":"XUZrp_l5CgEL","metadata":{"id":"XUZrp_l5CgEL"},"outputs":[],"source":["import pandas as pd\n","from tqdm import tqdm\n","from datasets import load_dataset, Dataset\n","from sentence_transformers import InputExample\n","from sentence_transformers.datasets import NoDuplicatesDataLoader\n","\n","# 为交叉编码器准备具有10 000个文档的小数据集\n","dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(10_000))\n","mapping = {2: 0, 1: 0, 0:1}\n","# 数据加载器\n","gold_examples = [\n","    InputExample(texts=[row[\"premise\"], row[\"hypothesis\"]], label=mapping[row[\"label\"]])\n","    for row in tqdm(dataset)\n","]\n","gold_dataloader = NoDuplicatesDataLoader(gold_examples, batch_size=32)\n","# 使用pandas DataFrame，以更方便地处理数据\n","gold = pd.DataFrame(\n","    {\n","    \"sentence1\": dataset[\"premise\"],\n","    \"sentence2\": dataset[\"hypothesis\"],\n","    \"label\": [mapping[label] for label in dataset[\"label\"]]\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"id":"UUJL-twpC8hl","metadata":{"id":"UUJL-twpC8hl"},"outputs":[],"source":["from sentence_transformers.cross_encoder import CrossEncoder\n","\n","# 在黄金数据集上训练交叉编码器\n","cross_encoder = CrossEncoder(\"bert-base-uncased\", num_labels=2)\n","cross_encoder.fit(\n","    train_dataloader=gold_dataloader,\n","    epochs=1,\n","    show_progress_bar=True,\n","    warmup_steps=100,\n","    use_amp=False\n",")"]},{"cell_type":"code","execution_count":null,"id":"9YPqD_HcDDL1","metadata":{"id":"9YPqD_HcDDL1"},"outputs":[],"source":["# 通过使用交叉编码器预测标注来准备白银数据集\n","silver = load_dataset(\n","    \"glue\", \"mnli\", split=\"train\"\n",").select(range(10_000, 50_000))\n","pairs = list(zip(silver[\"premise\"], silver[\"hypothesis\"]))"]},{"cell_type":"code","execution_count":null,"id":"WeLha3oNDF9c","metadata":{"id":"WeLha3oNDF9c"},"outputs":[],"source":["import numpy as np\n","\n","# 使用经过微调的交叉编码器标注句子对\n","output = cross_encoder.predict(\n","    pairs, apply_softmax=True,\n","show_progress_bar=True\n",")\n","silver = pd.DataFrame(\n","    {\n","        \"sentence1\": silver[\"premise\"],\n","        \"sentence2\": silver[\"hypothesis\"],\n","        \"label\": np.argmax(output, axis=1)\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"id":"lC5V_GRXDJcM","metadata":{"id":"lC5V_GRXDJcM"},"outputs":[],"source":["# 组合黄金数据集和白银数据集\n","data = pd.concat([gold, silver], ignore_index=True, axis=0)\n","data = data.drop_duplicates(subset=[\"sentence1\", \"sentence2\"], keep=\"first\")\n","train_dataset = Dataset.from_pandas(data, preserve_index=False)"]},{"cell_type":"code","execution_count":null,"id":"YO0PWG_UDL6t","metadata":{"id":"YO0PWG_UDL6t"},"outputs":[],"source":["from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n","\n","# 为STSB创建嵌入相似度评估器\n","val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n","evaluator = EmbeddingSimilarityEvaluator(\n","    sentences1=val_sts[\"sentence1\"],\n","    sentences2=val_sts[\"sentence2\"],\n","    scores=[score/5 for score in val_sts[\"label\"]],\n","    main_similarity=\"cosine\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"NEwfOH02DOb3","metadata":{"id":"NEwfOH02DOb3"},"outputs":[],"source":["from sentence_transformers import losses, SentenceTransformer\n","from sentence_transformers.trainer import SentenceTransformerTrainer\n","from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n","\n","# 定义模型\n","embedding_model = SentenceTransformer(\"bert-base-uncased\")\n","# 损失函数\n","train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n","# 定义训练参数\n","args = SentenceTransformerTrainingArguments(\n","    output_dir=\"augmented_embedding_model\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    warmup_steps=100,\n","    fp16=True,\n","    eval_steps=100,\n","    logging_steps=100,\n",")\n","# 训练模型\n","trainer = SentenceTransformerTrainer(\n","    model=embedding_model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    loss=train_loss,\n","    evaluator=evaluator\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"qkSuimljDW0X","metadata":{"id":"qkSuimljDW0X"},"outputs":[],"source":["evaluator(embedding_model)"]},{"cell_type":"markdown","id":"AhXDS0ZFDi0D","metadata":{"id":"AhXDS0ZFDi0D"},"source":["# 无监督学习"]},{"cell_type":"code","execution_count":null,"id":"TjoHyIkuDj04","metadata":{"id":"TjoHyIkuDj04"},"outputs":[],"source":["# 下载额外的分词器\n","import nltk\n","nltk.download(\"punkt\")\n","nltk.download('punkt_tab')"]},{"cell_type":"code","execution_count":null,"id":"Vj9t7jV_Dphu","metadata":{"colab":{"background_save":true},"id":"Vj9t7jV_Dphu"},"outputs":[],"source":["from tqdm import tqdm\n","from datasets import Dataset, load_dataset\n","from sentence_transformers.datasets import DenoisingAutoEncoderDataset\n","\n","# 创建一个一维的句子列表\n","mnli = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(25_000))\n","flat_sentences = list(mnli[\"premise\"]) + list(mnli[\"hypothesis\"])\n","# 为输入数据添加噪声\n","damaged_data = DenoisingAutoEncoderDataset(list(set(flat_sentences)))\n","# 创建数据集\n","train_dataset = {\"damaged_sentence\": [], \"original_sentence\": []}\n","for data in tqdm(damaged_data):\n","    train_dataset[\"damaged_sentence\"].append(data.texts[0])\n","    train_dataset[\"original_sentence\"].append(data.texts[1])\n","train_dataset = Dataset.from_dict(train_dataset)"]},{"cell_type":"code","execution_count":null,"id":"66YG-6xKDsUv","metadata":{"colab":{"background_save":true},"id":"66YG-6xKDsUv"},"outputs":[],"source":["train_dataset[0]"]},{"cell_type":"code","execution_count":null,"id":"9W-aRCh6Du54","metadata":{"colab":{"background_save":true},"id":"9W-aRCh6Du54"},"outputs":[],"source":["from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n","\n","# 为STSB创建嵌入相似度评估器\n","val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n","evaluator = EmbeddingSimilarityEvaluator(\n","    sentences1=val_sts[\"sentence1\"],\n","    sentences2=val_sts[\"sentence2\"],\n","    scores=[score/5 for score in val_sts[\"label\"]],\n","    main_similarity=\"cosine\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"lKR8d5XbDw5o","metadata":{"colab":{"background_save":true},"id":"lKR8d5XbDw5o"},"outputs":[],"source":["from sentence_transformers import models, SentenceTransformer\n","\n","# 创建嵌入模型\n","word_embedding_model = models.Transformer(\"bert-base-uncased\")\n","pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), \"cls\")\n","embedding_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"]},{"cell_type":"code","execution_count":null,"id":"_viEURuID0RO","metadata":{"colab":{"background_save":true},"id":"_viEURuID0RO"},"outputs":[],"source":["from sentence_transformers import losses\n","\n","# 使用去噪自编码器损失函数\n","train_loss = losses.DenoisingAutoEncoderLoss(\n","    embedding_model, tie_encoder_decoder=True\n",")\n","train_loss.decoder = train_loss.decoder.to(\"cuda\")"]},{"cell_type":"code","execution_count":null,"id":"VlDRni2GD29d","metadata":{"colab":{"background_save":true},"id":"VlDRni2GD29d"},"outputs":[],"source":["from sentence_transformers.trainer import SentenceTransformerTrainer\n","from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n","\n","# 定义训练参数\n","args = SentenceTransformerTrainingArguments(\n","    output_dir=\"tsdae_embedding_model\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=100,\n","    fp16=True,\n","    eval_steps=100,\n","    logging_steps=100,\n",")\n","# 训练模型\n","trainer = SentenceTransformerTrainer(\n","    model=embedding_model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    loss=train_loss,\n","    evaluator=evaluator\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"ytrmf2TXD50c","metadata":{"colab":{"background_save":true},"id":"ytrmf2TXD50c"},"outputs":[],"source":["# 评估训练好的模型\n","evaluator(embedding_model)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.19"}},"nbformat":4,"nbformat_minor":5}