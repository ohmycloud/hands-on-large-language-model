from transformers import AutoModelForCausalLM, AutoTokenizer
import click

text = """
English and CAPITALIZATION
üéµÈ∏ü
show_tokens False None elif == >= else: two tabs:" " Three tabs: "   "
12.0*50=600‚Äù
"""

colors_list = [
    '102;194;165', '252;141;98', '141;160;203',
    '231;138;195', '166;216;84', '255;217;47'
]

@click.command()
@click.option("--sentence", type=str, default=text, help="The sentence to tokenize")
@click.option("--tokenizer-name", type=click.Choice(["bert-base-uncased", "bert-base-cased", "soh", "temp"]))
def show_tokens(sentence, tokenizer_name):
    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
    token_ids = tokenizer(sentence).input_ids

    for idx, token in enumerate(token_ids):
        print(f'\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +
              tokenizer.decode(token) +
              '\x1b[0m',
              end=''
        )

if __name__ == "__main__":
    show_tokens()
